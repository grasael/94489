# -*- coding: utf-8 -*-
"""features+training_w_schoolmetro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H00phXNJvLgDgE3QxT8cS6gk5DyuSpnc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.dummy import DummyClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import make_column_transformer
from sklearn.metrics import confusion_matrix
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_curve, average_precision_score

data = pd.read_csv("data_imp_rural.csv").drop(columns=["need_statement"])

data.head()

data.not_fully_funded.value_counts()

y = data.not_fully_funded
X = data.drop('not_fully_funded', axis=1)

"""## Train-Validation-Test Split"""

X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=2, stratify=y_train_val)

ohe = OneHotEncoder(handle_unknown='ignore')

vectorizer_temp = CountVectorizer(stop_words='english')
built_in_stop_words = vectorizer_temp.get_stop_words()

custom_stop_words = ['my', 'students', 'need']

combined_stop_words = list(set(built_in_stop_words).union(custom_stop_words))

vectorizer_title = CountVectorizer(stop_words='english')
vectorizer_need_statement = CountVectorizer(stop_words=combined_stop_words)

ct = make_column_transformer(
    (ohe, ['resource_type','school_state','grade_level']),
    (vectorizer_title, 'title'),
    remainder='passthrough'
)

X_train['title'] = X_train['title'].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True)
X_test['title'] = X_test['title'].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True)

ct.fit(X_train)

X_train = ct.transform(X_train)
X_val = ct.transform(X_val)
X_test = ct.transform(X_test)

X_train.shape, y_train.shape

X_val.shape, y_val.shape

X_test.shape, y_test.shape

"""### Prepare train-validation-test split for two groups

Rural schools vs. Non rural schools
"""

feature_names = ct.get_feature_names_out()
school_rural_index = list(feature_names).index('remainder__is_rural')

from scipy.sparse import csr_matrix

school_rural_column_train = X_train[:, school_rural_index].toarray().flatten()
school_rural_column_val = X_val[:, school_rural_index].toarray().flatten()
school_rural_column_test = X_test[:, school_rural_index].toarray().flatten()

X_train_rural_1 = X_train[X_train[:, school_rural_index].toarray().flatten() == 1]
X_train_rural_0 = X_train[X_train[:, school_rural_index].toarray().flatten() == 0]

y_train_rural_1 = y_train[school_rural_column_train == 1]
y_train_rural_0 = y_train[school_rural_column_train == 0]

X_val_rural_1 = X_val[X_val[:, school_rural_index].toarray().flatten() == 1]
X_val_rural_0 = X_val[X_val[:, school_rural_index].toarray().flatten() == 0]

y_val_rural_1 = y_val[school_rural_column_val == 1]
y_val_rural_0 = y_val[school_rural_column_val == 0]

X_test_rural_1 = X_test[X_test[:, school_rural_index].toarray().flatten() == 1]
X_test_rural_0 = X_test[X_test[:, school_rural_index].toarray().flatten() == 0]

y_test_rural_1 = y_test[school_rural_column_test == 1]
y_test_rural_0 = y_test[school_rural_column_test == 0]

X_train_rural_1.shape, y_train_rural_1.shape

X_train_rural_0.shape, y_train_rural_0.shape

"""## Baseline"""

data_mag = data[data['is_rural'] == 1]
data_nomag = data[data['is_rural'] == 0]

y_rural = data_mag.not_fully_funded
X_rural = data_mag.drop('not_fully_funded', axis=1)

y_norural = data_nomag.not_fully_funded
X_norural = data_nomag.drop('not_fully_funded', axis=1)

X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)
X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=2, stratify=y_train_val)

X_rural_train_val2, X_rural_test2, y_rural_train_val2, y_rural_test2 = train_test_split(X_rural, y_rural, test_size=0.2, random_state=2, stratify=y_rural)
X_rural_train2, X_rural_val2, y_rural_train2, y_rural_val2 = train_test_split(X_rural_train_val2, y_rural_train_val2, test_size=0.2, random_state=2, stratify=y_rural_train_val2)

X_norural_train_val2, X_norural_test2, y_norural_train_val2, y_norural_test2 = train_test_split(X_norural, y_norural, test_size=0.2, random_state=2, stratify=y_norural)
X_norural_train2, X_norural_val2, y_norural_train2, y_norural_val2 = train_test_split(X_norural_train_val2, y_norural_train_val2, test_size=0.2, random_state=2, stratify=y_norural_train_val2)

X_test2_sorted = X_test2.sort_values(by='title_word_count', ascending=True)
X_mag_test2_sorted = X_rural_test2.sort_values(by='title_word_count', ascending=True)
X_nomag_test2_sorted = X_norural_test2.sort_values(by='title_word_count', ascending=True)

threshold = int(len(X_test2) * 0.306)
baseline_predictions = np.zeros(len(X_test2))
baseline_predictions[:threshold] = 1

rural_baseline = np.zeros(len(X_rural_test2))
rural_baseline[:threshold] = 1
norural_baseline = np.zeros(len(X_norural_test2))
norural_baseline[:threshold] = 1

baseline_recall = recall_score(y_test2, baseline_predictions)
print(f"Baseline Recall: {baseline_recall}")
baseline_precision = precision_score(y_test2, baseline_predictions)
print(f"Baseline Precision: {baseline_precision}")

print("For rural schools:")
rural_baseline_recall = recall_score(y_rural_test2, rural_baseline)
print(f"Baseline Recall: {rural_baseline_recall}")
rural_baseline_precision = precision_score(y_rural_test2, rural_baseline)
print(f"Baseline Precision: {rural_baseline_precision}")

print("For non-rural schools:")
norural_baseline_recall = recall_score(y_norural_test2, norural_baseline)
print(f"Baseline Recall: {norural_baseline_recall}")
norural_baseline_precision = precision_score(y_norural_test2, norural_baseline)
print(f"Baseline Precision: {norural_baseline_precision}")



"""## Models"""

feature_name_mapping = {
    # Primary Focus Subject Mappings
    "onehotencoder__primary_focus_subject_Mathematics": "Primary Focus: Mathematics",
    "onehotencoder__primary_focus_subject_Literature & Writing": "Primary Focus: Literature & Writing",
    "onehotencoder__primary_focus_subject_College & Career Prep": "Primary Focus: College & Career Prep",
    "onehotencoder__primary_focus_subject_Parent Involvement": "Primary Focus: Parent Involvement",
    "onehotencoder__primary_focus_subject_Literacy": "Primary Focus: Literacy",

    # Poverty Level
    "ordinalencoder__poverty_level": "Poverty Level",

    # Resource Type Mappings
    "onehotencoder__resource_type_Technology": "Resource Type: Technology",
    "onehotencoder__resource_type_Supplies": "Resource Type: Supplies",
    "onehotencoder__resource_type_Books": "Resource Type: Books",
    "onehotencoder__resource_type_Trips": "Resource Type: Trips",
    "onehotencoder__resource_type_Visitors": "Resource Type: Visitors",
    "onehotencoder__resource_type_Other": "Resource Type: Other",

    # Grade Level Mappings
    "onehotencoder__grade_level_Grades 3-5": "Grade Level: Grades 3-5",
    "onehotencoder__grade_level_Grades 6-8": "Grade Level: Grades 6-8",
    "onehotencoder__grade_level_Grades 9-12": "Grade Level: Grades 9-12",
    "onehotencoder__grade_level_Grades PreK-2": "Grade Level: Grades PK-2",

    # School State Mappings (examples for some states)
    "onehotencoder__school_state_CA": "School State: California",
    "onehotencoder__school_state_TX": "School State: Texas",
    "onehotencoder__school_state_NY": "School State: New York",
    "onehotencoder__school_state_FL": "School State: Florida",
    "onehotencoder__school_state_IL": "School State: Illinois",
    "onehotencoder__school_state_GA": "School State: Georgia",
    "onehotencoder__school_state_NC": "School State: North Carolina",
    "onehotencoder__school_state_MA": "School State: Massachusetts",
    "onehotencoder__school_state_AZ": "School State: Arizona",
    "onehotencoder__school_state_PA": "School State: Pennsylvania",
    "onehotencoder__school_state_OH": "School State: Ohio",
    "onehotencoder__school_state_MI": "School State: Michigan",
    "onehotencoder__school_state_WA": "School State: Washington",
    "onehotencoder__school_state_CO": "School State: Colorado",
    "onehotencoder__school_state_SC": "School State: South Carolina",
    "onehotencoder__school_state_MD": "School State: Maryland",
    "onehotencoder__school_state_NJ": "School State: New Jersey",
    "onehotencoder__school_state_IN": "School State: Indiana",
    "onehotencoder__school_state_AL": "School State: Alabama",
    "onehotencoder__school_state_LA": "School State: Louisiana",
    "onehotencoder__school_state_OR": "School State: Oregon",
    "onehotencoder__school_state_VA": "School State: Virginia",
    "onehotencoder__school_state_NM": "School State: New Mexico",
    "onehotencoder__school_state_UT": "School State: Utah",
    "onehotencoder__school_state_CT": "School State: Connecticut",
    "onehotencoder__school_state_KS": "School State: Kansas",
    "onehotencoder__school_state_MO": "School State: Missouri",
    "onehotencoder__school_state_NV": "School State: Nevada",
    "onehotencoder__school_state_ME": "School State: Maine",
    "onehotencoder__school_state_HI": "School State: Hawaii",
    "onehotencoder__school_state_ID": "School State: Idaho",
    "onehotencoder__school_state_WV": "School State: West Virginia",
    "onehotencoder__school_state_NE": "School State: Nebraska",
    "onehotencoder__school_state_VT": "School State: Vermont",
    "onehotencoder__school_state_SD": "School State: South Dakota",
    "onehotencoder__school_state_WY": "School State: Wyoming",
    "onehotencoder__school_state_ND": "School State: North Dakota",
    "onehotencoder__school_state_MN": "School State: Minnesota",
    "onehotencoder__school_state_KY": "School State: Kentucky",
    "onehotencoder__school_state_OK": "School State: Oklahoma",
    "onehotencoder__school_state_IA": "School State: Iowa",
    "onehotencoder__school_state_AR": "School State: Arkansas",
    "onehotencoder__school_state_MS": "School State: Mississippi",
    "onehotencoder__school_state_WI": "School State: Wisconsin",
    "onehotencoder__school_state_MT": "School State: Montana",
    "onehotencoder__school_state_TN": "School State: Tennessee",
    "onehotencoder__school_state_AK": "School State: Alaska",
    "onehotencoder__school_state_NH": "School State: New Hampshire",
    "onehotencoder__school_state_DE": "School State: Delaware",
    "onehotencoder__school_state_RI": "School State: Rhode Island",
    "onehotencoder__school_state_DC": "School State: District of Columbia",

    # School Characteristics
    "remainder__school_charter": "School Type: Charter",
    "remainder__school_magnet": "School Type: Magnet",
    "remainder__school_year_round": "School Year: Year-Round",
    "remainder__school_nlns": "School Type: NLNS",
    "remainder__school_kipp": "School Type: KIPP",
    "remainder__school_charter_ready_promise": "School Type: Charter Ready Promise",

    # Fulfillment & Cost
    "remainder__fulfillment_labor_materials": "Cost: Fulfillment Labor & Materials",

    # Essay and Description Counts
    "remainder__essay_word_count": "Essay Word Count",
    "remainder__description_word_count": "Description Word Count",

    # Other Feature Mappings
    "remainder__students_reached": "Number of Students Reached",
    "remainder__teacher_prefix": "Teacher Prefix",
    "remainder__primary_focus_area": "Primary Focus Area",
    "remainder__secondary_focus_area": "Secondary Focus Area",
    "remainder__need_word_count": "Need Word Count",
    "remainder__title_word_count": "Title Word Count",
    "remainder__sub_primary_focus_area": "Sub-Primary Focus Area",
    "onehotencoder__primary_focus_subject_Literacy": "Primary Focus: Literacy",
    "onehotencoder__primary_focus_subject_Parent Involvement": "Primary Focus: Parent Involvement",
    "onehotencoder__primary_focus_subject_Other": "Primary Focus: Other",
}

# Define the mapping function
def apply_feature_name_mapping(importance_df):
    importance_df['Feature'] = importance_df['Feature'].apply(lambda x: feature_name_mapping.get(x, x))
    return importance_df

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(class_weight = "balanced", max_iter=1000)
# trying to account for imbalance
lr.fit(X_train, y_train)

lr_y_valhat = lr.predict(X_val)
lr_y_rural_valhat = lr.predict(X_val_rural_1)
lr_y_norural_valhat = lr.predict(X_val_rural_0)

print(classification_report(y_val, lr_y_valhat, digits=4))
acc = accuracy_score(y_val, lr_y_valhat)
print("Accuracy: %.5f" % acc)

lr_y_test = lr.predict(X_test)

print("\nTuned LR Test Results:")
print(classification_report(y_test, lr_y_test, digits=4))
print(f"Accuracy: {accuracy_score(y_test, lr_y_test):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, lr_y_test, labels=[1, 0]))

print("Rural schools:")
print(classification_report(y_val_rural_1, lr_y_rural_valhat, digits=4))

print("Non-Rural schools:")
print(classification_report(y_val_rural_0, lr_y_norural_valhat, digits=4))

lr_coefficients = np.abs(lr.coef_).flatten()
feature_names = ct.get_feature_names_out()

lr_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': lr_coefficients})
lr_importance_df = apply_feature_name_mapping(lr_importance_df)
lr_importance_df = lr_importance_df.sort_values(by='Importance', ascending=False)

print(lr_importance_df['Feature'].tolist())
lr_importance_df.columns = lr_importance_df.columns.str.strip()

lr_importance_df_clean = lr_importance_df[~lr_importance_df['Feature'].str.contains("School State", na=False)].head(10)

plt.figure(figsize=(12, 15))
plt.barh(lr_importance_df_clean['Feature'], lr_importance_df_clean['Importance'], align='center')
plt.xlabel('Importance')
plt.title('Feature Importance from Logistic Regression (Absolute Coefficients)')
plt.gca().invert_yaxis()
plt.show()

"""## Logistic Regression With LASSO"""

from sklearn.linear_model import Lasso
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import mean_squared_error
from scipy.sparse import hstack
from sklearn.preprocessing import StandardScaler

# get titles from the dataset for bag of words analysis

scaler = StandardScaler(with_mean=False)

titles = data["title"]
target = data["not_fully_funded"]

# converts titles into word count vectors for lasso
# vectorizer = CountVectorizer()
# X_titles = vectorizer.fit_transform(titles)
# print("Total number of features in X_titles after vectorization:", X_titles.shape[1])

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

X_val_rural_1_scaled = scaler.transform(X_val_rural_1)
X_val_rural_0_scaled = scaler.transform(X_val_rural_0)

logistic_lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000)

logistic_lasso.fit(X_train_scaled, y_train)

y_val_lasso = logistic_lasso.predict(X_val_scaled)
print(classification_report(y_val, y_val_lasso, digits=4))

y_rural_val_lasso = logistic_lasso.predict(X_val_rural_1_scaled)

print("For rural schools:")
print(classification_report(y_val_rural_1, y_rural_val_lasso, digits=4))

y_norural_val_lasso = logistic_lasso.predict(X_val_rural_0_scaled)
print("For non-rural schools:")
print(classification_report(y_val_rural_0, y_norural_val_lasso, digits=4))

"""## XGBoost"""

import xgboost as xgb
from xgboost import XGBClassifier

xgb = XGBClassifier(eval_metric='logloss', scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]))
xgb.fit(X_train, y_train)
xgb_y_val = xgb.predict(X_val)

print("\nXGBoost Results:")
print(classification_report(y_val, xgb_y_val, digits=4))
print(f"Accuracy: {accuracy_score(y_val, xgb_y_val):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_val, xgb_y_val, labels=[1, 0]))

xgb_y_test = xgb.predict(X_test)

print("\XGB Test Results:")
print(classification_report(y_test, xgb_y_test, digits=4))
print(f"Accuracy: {accuracy_score(y_test, xgb_y_test):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, xgb_y_test, labels=[1, 0]))

y_rural_val = xgb.predict(X_val_rural_1)
y_norural_val = xgb.predict(X_val_rural_0)

print("rural schools XGBoost Results:")
print(classification_report(y_val_rural_1, y_rural_val, digits=4))

print("Non-rural schools XGBoost Results:")
print(classification_report(y_val_rural_0, y_norural_val, digits=4))



xgboost_importances = xgb.feature_importances_
xgb_importance_df = pd.DataFrame({'Feature': ct.get_feature_names_out(), 'Importance': xgboost_importances})
xgb_importance_df = apply_feature_name_mapping(xgb_importance_df)
xgb_importance_df_clean = xgb_importance_df[~xgb_importance_df['Feature'].str.contains("School State", na=False)].head(10)
xgb_importance_df_clean = xgb_importance_df_clean.sort_values(by='Importance', ascending=True).head(10)
plt.figure(figsize=(12, 15))
plt.barh(xgb_importance_df_clean['Feature'], xgb_importance_df_clean['Importance'], align='center')
plt.xlabel('Importance')
plt.title('Feature Importance from XGBoost')

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier(random_state=0)
gbc.fit(X_train, y_train)
gbc_y_val = gbc.predict(X_val)

print("Gradient Boosting Results:")
print(classification_report(y_val, gbc_y_val, digits=4))
print(f"Accuracy: {accuracy_score(y_val, gbc_y_val):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_val, gbc_y_val, labels=[1, 0]))

gbc_y_rural_val = gbc.predict(X_val_rural_1)
gbc_y_norural_val = gbc.predict(X_val_rural_0)

print("rural schools Gradient Boosting Results:")
print(classification_report(y_val_rural_1, gbc_y_rural_val, digits=4))

print("Non-rural schools Gradient Boosting Results:")
print(classification_report(y_val_rural_0, gbc_y_norural_val, digits=4))

"""## Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()

nb.fit(X_train, y_train)
nb_y_val = nb.predict(X_val)

print("Naive Bayes Results:")
print(classification_report(y_val, nb_y_val,digits=4))
print(f"Accuracy: {accuracy_score(y_val, nb_y_val):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_val, nb_y_val, labels=[1, 0]))

nb_y_rural_val = nb.predict(X_val_rural_1)
nb_y_norural_val = nb.predict(X_val_rural_0)

print("rural schools Naive Bayes Results:")
print(classification_report(y_val_rural_1, nb_y_rural_val, digits=4))

print("Non-rural schools Naive Bayes Results:")
print(classification_report(y_val_rural_0, nb_y_norural_val, digits=4))

"""## CatBoost"""

!pip install catboost

from catboost import CatBoostClassifier

catboost_model = CatBoostClassifier(iterations=500,
                                    depth=6,
                                    learning_rate=0.1,
                                    loss_function='Logloss',
                                    cat_features=[]  # Add the indices of categorical features here if needed
                                    )

catboost_model.fit(X_train, y_train)

cb_y_val = catboost_model.predict(X_val)
print(classification_report(y_val, cb_y_val, digits=4))

print("rural schools CatBoost Results:")
cb_y_rural_val = catboost_model.predict(X_val_rural_1)
print(classification_report(y_val_rural_1, cb_y_rural_val, digits=4))

print("Non-rural schools CatBoost Results:")
cb_y_norural_val = catboost_model.predict(X_val_rural_0)
print(classification_report(y_val_rural_0, cb_y_norural_val, digits=4))

"""## XGBoost Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],             # Number of trees
    'max_depth': [3, 4, 5],                     # Depth of the tree
    'learning_rate': [0.01, 0.1, 0.2],          # Step size shrinkage
    'subsample': [0.6, 0.8, 1.0],               # Subsample ratio of the training set
    # 'colsample_bytree': [0.6, 0.8, 1.0],        # Subsample ratio of features per tree
    # 'gamma': [0, 0.1, 0.3],                     # Minimum loss reduction for further partition
    # 'reg_alpha': [0, 0.1, 0.5],                 # L1 regularization term
    # 'reg_lambda': [1, 1.5, 2],                  # L2 regularization term
}

grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,
                           scoring='recall', cv=3, verbose=1)

grid_search.fit(X_train, y_train)

# Best parameters and score
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-validation Score: {grid_search.best_score_}")

# Get the best estimator (model) from GridSearchCV
best_xgb_model = grid_search.best_estimator_

# Predict on the validation set
xgb_y_val = best_xgb_model.predict(X_val)

# Evaluate the performance on validation set
recall = recall_score(y_val, xgb_y_val)
print(f"Validation Recall: {recall}")

# Predict on the test set and evaluate
xgb_y_test = best_xgb_model.predict(X_test)
test_recall = recall_score(y_test, xgb_y_test)
print(f"Test Recall: {test_recall}")

"""### Tuned XGBoost Results

"""

tuned_xgb = XGBClassifier(eval_metric='logloss',
                          scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),
                          learning_rate = 0.01,
                          max_depth = 4,
                          n_estimators = 50,
                          subsample = 0.6)

tuned_xgb.fit(X_train, y_train)
tuned_xgb_y_val = xgb.predict(X_val)

print("\nTuned XGBoost Validation Results:")
print(classification_report(y_val, tuned_xgb_y_val, digits=4))
print(f"Accuracy: {accuracy_score(y_val, tuned_xgb_y_val):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_val, tuned_xgb_y_val, labels=[1, 0]))

tuned_xgb_y_test = xgb.predict(X_test)

print("\nTuned XGBoost Test Results:")
print(classification_report(y_test, tuned_xgb_y_test, digits=4))
print(f"Accuracy: {accuracy_score(y_test, tuned_xgb_y_test):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, tuned_xgb_y_test, labels=[1, 0]))

tuned_xgb_y_mag_test = xgb.predict(X_test_magnet_1)
tuned_xgb_y_nomag_test = xgb.predict(X_test_magnet_0)

print("Magnet schools Tuned XGBoost Test Set Results:")
print(classification_report(y_test_magnet_1, tuned_xgb_y_mag_test, digits=4))

print("Non-Magnet schools Tuned XGBoost Test Set Results:")
print(classification_report(y_test_magnet_0, tuned_xgb_y_nomag_test, digits=4))

"""## Tuning Naive Bayes"""

param_grid = {
  'alpha': [0.1, 0.5, 1.0, 5.0],  # Example values for smoothing parameter
  'fit_prior': [True, False]      # Whether to learn class prior probabilities
}

grid_search = GridSearchCV(
  estimator=MultinomialNB(),
  param_grid=param_grid,
  scoring='recall',
  cv=5,                # 5-fold cross-validation
  verbose=1,           # Progress output
  n_jobs=-1            # Use all processors
)

# Run grid search
grid_search.fit(X_train, y_train)

# Best parameters and score
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-validation Score: {grid_search.best_score_}")

# Get the best estimator (model) from GridSearchCV
best_nb_model = grid_search.best_estimator_

# Predict on the validation set
nb_y_val = best_nb_model.predict(X_val)

# Evaluate the performance on validation set
recall = recall_score(y_val, nb_y_val)
print(f"Validation Recall: {recall}")

# Predict on the test set and evaluate
nb_y_test = best_nb_model.predict(X_test)
test_recall = recall_score(y_test, nb_y_test)
print(f"Test Recall: {test_recall}")

"""### Tuned Naive Bayes Results"""

tuned_nb = MultinomialNB(alpha = 0.5, fit_prior = False)

tuned_nb.fit(X_train, y_train)
tuned_nb_y_val = tuned_nb.predict(X_val)

print("\nTuned Naive Bayes Validation Results:")
print(classification_report(y_val, tuned_nb_y_val, digits=4))
print(f"Accuracy: {accuracy_score(y_val, tuned_nb_y_val):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_val, tuned_nb_y_val, labels=[1, 0]))

tuned_nb_y_test = tuned_nb.predict(X_test)

print("\nTuned Naive Bayes Test Results:")
print(classification_report(y_test, tuned_nb_y_test, digits=4))
print(f"Accuracy: {accuracy_score(y_test, tuned_nb_y_test):.5f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, tuned_nb_y_test, labels=[1, 0]))

tuned_nb_y_rural_test = tuned_nb.predict(X_test_rural_1)
tuned_nb_y_norural_test = tuned_nb.predict(X_test_rural_0)

print("rural schools Tuned Naive Bayes Test Set Results:")
print(classification_report(y_test_rural_1, tuned_nb_y_rural_test, digits=4))

print("Non-rural schools Tuned Naive Bayes Test Set Results:")
print(classification_report(y_test_rural_0, tuned_nb_y_norural_test, digits=4))

"""### Feature Importances"""

import numpy as np
import matplotlib.pyplot as plt

log_probabilities = tuned_nb.feature_log_prob_
importance_scores = np.exp(log_probabilities)  # Convert log-probabilities to probabilities

# Filter features to exclude those containing "School State"
filtered_features = [feature for feature in feature_names if "school_state" not in feature.lower()]
filtered_indices = [i for i, feature in enumerate(feature_names) if "school_state" not in feature.lower()]

# Filter the probabilities
filtered_probabilities = importance_scores[:, filtered_indices]

def apply_naming(features):
  return [feature_name_mapping.get(f.lower(), f) for f in features]

filtered_features = apply_naming(filtered_features)

# Plot the top 10 features for each class
for i, class_label in enumerate(tuned_nb.classes_):
    print(f"Class {class_label}:")
    sorted_indices = np.argsort(filtered_probabilities[i])[::-1]

    # Select the top 10 features
    top_features = [filtered_features[idx] for idx in sorted_indices[:10]]
    top_probabilities = filtered_probabilities[i][sorted_indices[:10]]

    # print the probabilities for reference
    for idx in sorted_indices[:10]:
        feature_idx = filtered_indices[idx]
        print(f"  {filtered_features[idx]}: {filtered_probabilities[i, idx]:.4f}")

features = [
    "Essay Word Count",
    "Number of Students Reached",
    "Description Word Count",
    "Cost: Fulfillment Labor & Materials",
    "Need Word Count",
    "Title Word Count",
    "Grade level: Grades PreK-2",
    "Resource type: Technology",
    "Grade level: Grades 3-5",
    "Resource type: Supplies"
]

importances = [
    0.6227,
    0.1592,
    0.0852,
    0.0626,
    0.0430,
    0.0115,
    0.0010,
    0.0009,
    0.0007,
    0.0006
]

# Create a DataFrame
df = pd.DataFrame({
    'Feature': features,
    'Importance': importances
})

# Sort by Importance in descending order
df = df.sort_values(by='Importance', ascending=True)

# Plotting the bar chart
plt.figure(figsize=(10, 6))
plt.barh(df['Feature'], df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.title('Feature Importance in Naive Bayes of classifying as not fully funded')
plt.show()

word_count_index = list(feature_names).index('remainder__essay_word_count')

results = []

for word_count_value in range(0, 100, 10):  # Test word counts from 1 to 100
    test_instance = np.zeros(X_train.shape[1])  # Initialize with zeros
    test_instance[word_count_index] = word_count_value  # Set the word_count feature

    predicted_class = tuned_nb.predict([test_instance])[0]
    probabilities = tuned_nb.predict_proba([test_instance])[0]

    # Append the results as a tuple to the list
    results.append({
        'Word Count': word_count_value,
        'Predicted Class': predicted_class,
        'Class 0 Probability': round(probabilities[0], 3),
        'Class 1 Probability': round(probabilities[1], 3)
    })

df_results = pd.DataFrame(results)

# Create a figure and axes
fig, ax = plt.subplots()

# Plot the DataFrame as a table
table = ax.table(cellText=df_results.values, colLabels=df_results.columns, loc='center')

# Remove axes
ax.axis('off')

# Show the plot
plt.show()

students_reached_index = list(feature_names).index('remainder__students_reached')

print("\nEffect of Students Reached on Prediction:")
for student_count in range(1, 100, 10):  # Test word counts from 1 to 15
    test_instance = np.zeros(X_train.shape[1])  # Initialize with zeros
    test_instance[students_reached_index] = student_count  # Set the word_count feature
    predicted_class = tuned_nb.predict([test_instance])[0]
    probabilities = tuned_nb.predict_proba([test_instance])[0]
    print(f"Students Reached: {student_count}, Predicted class: {predicted_class}, Probabilities: {probabilities}")

"""### PR-k curve"""

tuned_nb_probs = tuned_nb.predict_proba(X_test)[:, 1]
nb_precision, nb_recall, thresholds = precision_recall_curve(y_test, tuned_nb_probs)

# Plot PR-K (Precision and Recall vs. Threshold) for XGBoost
plt.figure(figsize=(10, 6))
plt.plot(thresholds, nb_precision[:-1], label='Precision')
plt.plot(thresholds, nb_recall[:-1], label='Recall')
plt.xlabel('Threshold')
plt.ylabel('Score')
plt.title('PR-K (Precision-Recall vs. Threshold) for Naive Bayes')
plt.legend()
plt.show()

